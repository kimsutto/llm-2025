import json
import pickle
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import os

# 1. ì²­í¬ ë¡œë”©
def load_chunks(json_path: str):
    with open(json_path, 'r', encoding='utf-8') as f:
        chunks_data = json.load(f)
    return chunks_data

# 2. ì„ë² ë”© ìƒì„±
def embed_chunks(model, metadata: list[dict]) -> np.ndarray:
    prompts = [
        f"passage: ì´ ì½”ë“œëŠ” vueì˜ {entry['name']} ì»´í¬ë„ŒíŠ¸ ë˜ëŠ” í•¨ìˆ˜ì´ë©°, ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n{entry['code']}"
        for entry in metadata
    ]   

    embeddings = model.encode(prompts, normalize_embeddings=True)
    return np.array(embeddings).astype('float32')

# 3. FAISS + ë©”íƒ€ë°ì´í„° ì €ì¥
def save_faiss_index(vectors: np.ndarray, metadata: list[dict], output_dir: str):
    os.makedirs(output_dir, exist_ok=True)

    dim = vectors.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(vectors)
    faiss.write_index(index, os.path.join(output_dir, 'faiss.index'))

    with open(os.path.join(output_dir, 'metadata.pkl'), 'wb') as f:
        pickle.dump(metadata, f)

# 4. ì „ì²´ ì‹¤í–‰
def run_pipeline(json_path: str, output_dir: str):
    print("ğŸ“¦ ì²­í¬ ë¡œë”© ì¤‘...")
    chunks_data = load_chunks(json_path)

    # chunks = [entry["code"] for entry in chunks_data]
    metadata = [
        {
            "file": entry["filePath"],
            "name": entry.get("name", "unknown"),
            "code": entry["code"]
        }
        for entry in chunks_data
    ]

    print(f"ğŸ§  ì²­í¬ ìˆ˜: {len(metadata)}")

    print("ğŸ“¥ ëª¨ë¸ ë¡œë”© ì¤‘...")
    # model = SentenceTransformer("intfloat/multilingual-e5-large-instruct")
    model = SentenceTransformer("../../multilingual-e5-large-instruct")


    print("ğŸ”¢ ì„ë² ë”© ì¤‘...")
    vectors = embed_chunks(model, metadata)


    print("ğŸ’¾ FAISS ì €ì¥ ì¤‘...")
    save_faiss_index(vectors, metadata, output_dir)

    print("âœ… ì €ì¥ ì™„ë£Œ â†’", output_dir)


run_pipeline("../data/vue_chunks_annotated.json", "../data/output_faiss")
